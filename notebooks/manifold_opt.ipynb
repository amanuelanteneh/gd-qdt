{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c7a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "from torch import vstack, hstack, tensor\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "from quantum import coherent_ket, povm_fidelity, coherent_dm\n",
    "from loss import phase_sensitive_loss_gd\n",
    "from utils import random_stiefel, unstack, check_povm, grid_points, plot_matrix, on_stiefel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2706951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3  # number of POVM outcomes\n",
    "N = 6  # Hilbert space dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d0c19",
   "metadata": {},
   "source": [
    "### True POVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a2e1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is true POVM valid? Yes\n"
     ]
    }
   ],
   "source": [
    "# random POVM\n",
    "true_povm_factors = random_stiefel(M*N, N) \n",
    "true_povm_factors = unstack(true_povm_factors, M=M, N=N) \n",
    "true_povm = [E.H @ E for E in true_povm_factors]  # true POVM for data generation\n",
    "\n",
    "# binary detection POVM\n",
    "# M = 2\n",
    "# E1 = th.diag( tensor([1.0] + [0.0]*(N-1), dtype=th.complex128) )\n",
    "# E2 = th.eye(N) - E1\n",
    "# true_povm = [E1, E2]\n",
    "\n",
    "# PNR POVM\n",
    "# true_povm = []\n",
    "# for m in range(M):\n",
    "#     povm_diag = th.zeros(N, dtype=th.complex128)\n",
    "#     povm_diag[m] = 1.0\n",
    "#     true_povm.append( th.diag(povm_diag) )\n",
    "\n",
    "print(f'Is true POVM valid? {\"Yes\" if check_povm(true_povm) else \"No\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f491cc4",
   "metadata": {},
   "source": [
    "### Probe states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "787bafe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of probes is: [900, 6] should be [900, 6].\n"
     ]
    }
   ],
   "source": [
    "num_probes = 30  # num_probes will actually be this squared\n",
    "max_amp = sqrt(4.0)   # max coordinate in phase space that will be spanned in one direction is max_amp^2\n",
    "\n",
    "# generate num_probes^2 state probes each from circles of increasing radius\n",
    "# complex_amps = np.array([circle_points(num_probes, R=R) for R in np.linspace(0.1, max_amp, num_probes) ]).flatten()\n",
    "complex_amps = grid_points(num_probes, xlim=(-max_amp, max_amp), ylim=(-max_amp, max_amp), dtype=th.complex128)\n",
    "\n",
    "probes = vstack([ coherent_ket(alpha, N) for alpha in complex_amps ])\n",
    "\n",
    "print(f\"Shape of probes is: {list(probes.shape)} should be {[num_probes**2, N]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8739f6bc",
   "metadata": {},
   "source": [
    "### Target matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2caf52ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of targets is: [900, 3] should be [900, 3].\n"
     ]
    }
   ],
   "source": [
    "# targets = []\n",
    "# for probe in probes:\n",
    "#     probe_probs = []\n",
    "#     for E in true_povm:\n",
    "#         prob = (probe.conj().T @ E @ probe).real\n",
    "#         probe_probs.append(prob)\n",
    "#     probe_probs = tensor(probe_probs)\n",
    "#     targets.append(probe_probs)\n",
    "\n",
    "# targets = vstack(targets).real\n",
    "targets = th.einsum(\"bi,mij,bj->bm\", probes.conj(), th.stack(true_povm), probes).real\n",
    "\n",
    "print(f\"Shape of targets is: {list(targets.shape)} should be {[num_probes**2, M]}.\")\n",
    "\n",
    "for i in range(targets.shape[0]):\n",
    "    if th.sum(targets[0]).item() - 1.0 > 1e-6:\n",
    "        print(f\"Warning: Sum of target probabilities for probe {i} is {th.sum(targets[i]).item()} (should be 1.0)\")\n",
    "\n",
    "# probes = th.vstack([coherent_dm(alpha, N) for alpha in complex_amps ]).reshape(num_probes**2, N, N)\n",
    "\n",
    "# plot_matrix(\n",
    "#     targets.numpy()[:5, :10],\n",
    "#     title=\"Target Probability Matrix\",\n",
    "#     cmap=\"viridis\",\n",
    "#     show_values= not False,\n",
    "#     xlabel=r\"$\\langle \\alpha_i|E_m|\\alpha_i\\rangle$\",\n",
    "#     ylabel=r\"$|\\alpha_i\\rangle$\",\n",
    "#     colorbar=True,\n",
    "#     figsize=(6, 5),\n",
    "#     vmin=None,\n",
    "#     vmax=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbfabfa",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ee4908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelities:  [0.5484820755217888, 0.6434545651061145, 0.6005578830517199]\n",
      "Mean fidelity is 0.5974981745598744\n",
      "|| I - ΣAi†Ai ||2: 5.07835799375251e-16\n"
     ]
    }
   ],
   "source": [
    "lam = 1e-4  # regularization weight\n",
    "current_lr = 0.01  # learning rate\n",
    "lr_decay = 0.99  # learning rate decay factor\n",
    "device = 'cuda'\n",
    "\n",
    "factors = random_stiefel(M*N, N).to(device)  # initialize POVM factors\n",
    "\n",
    "factors_unstacked = unstack(factors, N=N, M=M).to('cpu')\n",
    "pred_povm_full = th.matmul(factors_unstacked.conj().transpose(-1, -2), factors_unstacked)\n",
    "Fs = [ povm_fidelity(pred_povm_full[i], true_povm[i]) for i in range(M) ]\n",
    "print(\"Fidelities: \", Fs)\n",
    "print(f\"Mean fidelity is {sum(Fs)/len(Fs)}\")\n",
    "print(f\"|| I - ΣAi†Ai ||2: {th.linalg.norm(th.eye(N).to(device) - factors.H @ factors, ord=2).item()}\")\n",
    "\n",
    "factors.requires_grad = True\n",
    "\n",
    "# optimizer = SGD([factors], lr=initial_lr)\n",
    "# scheduler = ExponentialLR(optimizer, gamma=lr_decay) # Decay LR by gamma every time called\n",
    "\n",
    "probes = probes.to(device)\n",
    "targets = targets.to(device)\n",
    "dataset = TensorDataset(probes, targets)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 20\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91204658",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2f9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning POVM:   0%|          | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m probes_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     47\u001b[0m     L \u001b[38;5;241m=\u001b[39m phase_sensitive_loss_gd(targets_batch, factors, probes_batch, lam)\n\u001b[0;32m---> 48\u001b[0m     \u001b[43mL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     51\u001b[0m         normed_G \u001b[38;5;241m=\u001b[39m factors\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m/\u001b[39m (th\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(factors\u001b[38;5;241m.\u001b[39mgrad, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-12\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "iterations = 250\n",
    "I = th.eye(2*N, dtype=th.complex128).to(device) # identity matrix for retraction step\n",
    "losses = []\n",
    "lr_vals = []\n",
    "\n",
    "for step in tqdm(range(iterations), desc=\"Learning POVM\"):\n",
    "    lr_vals.append(current_lr)\n",
    "    completeness_cond = th.linalg.norm(th.eye(N).to(device) - factors.H @ factors, ord=2).item()\n",
    "    if completeness_cond > 1e-5:\n",
    "        print(f\"Warning: POVM not valid at step {step+1} is: {completeness_cond}\") \n",
    "    \n",
    "    batch_losses = []\n",
    "\n",
    "    for probes_batch, targets_batch in loader:\n",
    "\n",
    "        # Compute batch loss\n",
    "        L = phase_sensitive_loss_gd (targets_batch, factors, probes_batch, lam)\n",
    "\n",
    "        L.backward()\n",
    "\n",
    "        with th.no_grad():\n",
    "            # --- Retraction step ---\n",
    "            normed_G = factors.grad / th.linalg.norm(factors.grad, ord=2)\n",
    "            A = th.hstack([normed_G, factors])      # (M*N, 2N)\n",
    "            B = th.hstack([factors, -normed_G])     # (M*N, 2N)\n",
    "\n",
    "            # Conjugate gradient retraction\n",
    "            inv_term = th.linalg.inv(I + (current_lr/2)*(B.conj().T @ A))\n",
    "            st_grad = A @ inv_term @ B.conj().T @ factors\n",
    "            factors -= current_lr * st_grad.data  # .data to avoid tracking in autograd\n",
    "        \n",
    "        # Zero gradients\n",
    "        factors.grad.zero_()\n",
    "        \n",
    "        batch_losses.append(L.item())\n",
    "        current_lr *= lr_decay  # decay learning rate manually\n",
    "\n",
    "    #scheduler.step()\n",
    "    losses.append(sum(batch_losses) / len(batch_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 9.09e-02\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAGzCAYAAAAlqLNlAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAANLtJREFUeJzt3Xl8VPXB/v3rzCSTjWSSkJAFAmEVw6oQUrQgFirSFhHsXWpbi9TqY41tldva27tPFdtaq/3pTZVUe/+6oNb2UVuX1rZuCLhRiVC0EEB2AtkIkH2fOc8fSYaJREzCJN+Zyef9eqUzc+bMzMXpSC7O+Z7vsWzbtgUAAABJksN0AAAAgGBCOQIAAPBDOQIAAPBDOQIAAPBDOQIAAPBDOQIAAPBDOQIAAPBDOQIAAPBDOQIAAPBDOQIAAPATYTpAMPN6vSopKVF8fLwsyzIdBwAA9IBt26qtrVVmZqYcjt7vBwr7cvTiiy/qP//zP+X1evX9739f3/zmN3v82pKSEmVlZfVjOgAA0F+Ki4s1YsSIXr/OCucLz7a1tSknJ0cbNmyQ2+3WjBkz9M4772jo0KE9en11dbUSExNVXFyshISEfk4LAAACoaamRllZWaqqqpLb7e7168N6z9GWLVs0adIkDR8+XJK0aNEivfLKK7r66qt79PrOQ2kJCQmUIwAAQkxfh8QE9YDsN954Q4sXL1ZmZqYsy9Lzzz9/xjoFBQXKzs5WdHS08vLytGXLFt9zJSUlvmIkScOHD9exY8cGIjoAAAhRQV2O6uvrNW3aNBUUFHT7/FNPPaVVq1bprrvu0rZt2zRt2jQtXLhQFRUVffq85uZm1dTUdPkBAACDS1CXo0WLFuknP/mJli5d2u3zDz74oK6//nqtXLlSOTk5evTRRxUbG6vf/va3kqTMzMwue4qOHTumzMzMj/28e++9V2632/fDYGwAAAafoC5HZ9PS0qKtW7dqwYIFvmUOh0MLFizQ5s2bJUmzZs3Sjh07dOzYMdXV1ekf//iHFi5c+LHveccdd6i6utr3U1xc3O9/DgAAEFxCdkB2ZWWlPB6P0tLSuixPS0vT7t27JUkRERF64IEHdOmll8rr9er2228/65lqUVFRioqK6tfcAAAguIVsOeqpK664QldccYXpGAAAIESE7GG1lJQUOZ1OlZeXd1leXl6u9PR0Q6kAAECoC9ly5HK5NGPGDK1fv963zOv1av369Zo9e7bBZAAAIJQF9WG1uro67du3z/f44MGD2r59u5KTkzVy5EitWrVKK1as0MyZMzVr1iytWbNG9fX1WrlypcHUAAAglAV1OXrvvfd06aWX+h6vWrVKkrRixQqtW7dOy5cv1/Hjx3XnnXeqrKxM06dP10svvXTGIG0AAICeCutrq52rmpoaud1uVVdXc/kQAABCxLn+/g7ZMUcAAAD9gXJkSE1Tq4pKuDwJAADBJqjHHIWr0upGzb73dUU4LO368eWKdNJRAQAIFvxWNiAtPlqxLqfavLaOnGwwHQcAAPihHBngcFgakxonSdpXUWc4DQAA8Ec5MmRs6hBJ0v7jlCMAAIIJ5agbBQUFysnJUW5ubr99xrjOclRR32+fAQAAeo9y1I38/HwVFRWpsLCw3z5j7LD2crSPPUcAAAQVypEh4zrK0YGKOjEPJwAAwYNyZMioobFyWFJtc5uO1zabjgMAADpQjgyJinBqZHKsJM5YAwAgmFCODOo8tMYZawAABA/KkUGnT+fnjDUAAIIF5cigznLEYTUAAIIH5cigsRxWAwAg6FCODOqcCLK0ukl1zW2G0wAAAIlyZJQ7NlIpQ6IkSQfYewQAQFCgHBk2tuMCtBxaAwAgOFCODPNdRoRB2QAABAXKkWFcgBYAgOBCOTKMM9YAAAgulCPDOmfJPnSiXm0er+E0AACAcmRYRkK0YiKdavXYOnKywXQcAAAGPcpRNwoKCpSTk6Pc3Nx+/yyHw9KYjjPWGJQNAIB5lKNu5Ofnq6ioSIWFhQPyeacvQMugbAAATKMcBYHTF6BlzxEAAKZRjoIAF6AFACB4UI6CwDi/0/lt2zacBgCAwY1yFASyU2LlsKTapjYdr2s2HQcAgEGNchQEoiKcGpkcK4lDawAAmEY5ChKnB2VzxhoAACZRjoKE7zIi7DkCAMAoylGQGMfp/AAABAXKUZAYO6x9lmz2HAEAYBblKEh0jjkqqW5SfXOb4TQAAAxelKMgkRjrUsoQlyTpAIOyAQAwhnIURMYw7ggAAOMoR0Gkc6Zs5joCAMAcylEQ4QK0AACYRzkKImNT289YY88RAADmUI6CSOdhtUMn6tXm8RpOAwDA4EQ5CiKZ7hhFRzrU6rFVfKrRdBwAAAYlylEQcTgsjUlhUDYAACZRjrpRUFCgnJwc5ebmDvhndx5aY1A2AABmUI66kZ+fr6KiIhUWFg74Z/vOWGPPEQAARlCOgoxvriP2HAEAYATlKMj4X4DWtm3DaQAAGHwoR0Eme2icHJZU09Sm43XNpuMAADDoUI6CTHSkU1nJsZKk/RVcgBYAgIFGOQpCXEYEAABzKEdBiAvQAgBgDuUoCHVeY409RwAADDzKURDqPKx24DhjjgAAGGiUoyDUWY6OVTWqvrnNcBoAAAYXylEQSopzaWicS5J0sJK9RwAADCTKUZDq3HvEoGwAAAYW5ShIjeUCtAAAGEE5ClKcsQYAgBmUoyDFXEcAAJhBOQpSnWOODlU2qM3jNZwGAIDBg3IUpIYnxig60qEWj1dHTzWajgMAwKBBOQpSDoelMSkcWgMAYKBRjoIYZ6wBADDwKEdBjDPWAAAYeJSjIMYZawAADDzKUTcKCgqUk5Oj3Nxcozk6z1jbf7xetm0bzQIAwGBBOepGfn6+ioqKVFhYaDTH6JQ4WZZU3diqyroWo1kAABgsKEdBLDrSqaykWEmMOwIAYKBQjoIcg7IBABhYlKMgx6BsAAAGFuUoyPkPygYAAP2PchTkOvcc7WfPEQAAA4JyFOQ69xwdq2pUQ0ub4TQAAIQ/ylGQS4pzKTnOJUk6wKE1AAD6HeUoBIxL5RprAAAMFMpRCBg7rON0fsYdAQDQ7yhHIYAz1gAAGDiUoxAwlrmOAAAYMJSjENA55uhgZb08Xi5ACwBAf6IchYDhiTGKinCoxePV0VMNpuMAABDWKEchwOGwNCaVQ2sAAAwEylGI4AK0AAAMDMpRiOACtAAADAzKUYjgdH4AAAYG5ShEjPUbc2TbnLEGAEB/oRyFiDGpcbIsqbqxVSfqW0zHAQAgbFGOQkR0pFMjkmIkcRkRAAD6E+UohIxj3BEAAP2OchRCxjLXEQAA/Y5yFEI6r7HGXEcAAPQfylEIYa4jAAD6H+UohHQeVjtW1ajGFo/hNAAAhCfKUTcKCgqUk5Oj3Nxc01G6SI5zKSk2UpJ0oJK9RwAA9AfKUTfy8/NVVFSkwsJC01HOwKE1AAD6F+UoxHAZEQAA+hflKMSM44w1AAD6FeUoxPj2HHFYDQCAfkE5CjGd5ehAZb08Xi5ACwBAoFGOQszwpBhFRTjU0ubV0VMNpuMAABB2KEchxumwNDolThLjjgAA6A+UoxDkG5RdwRlrAAAEGuUoBHEBWgAA+g/lKARxAVoAAPoP5SgEjUulHAEA0F8oRyFodEqcLEs61dCqE3XNpuMAABBWKEchKMbl1PDEGElcRgQAgECjHIUoLkALAED/oByFqLGMOwIAoF9QjkIUF6AFAKB/UI5CFHMdAQDQPyhHIWpsavslRI5VNaqxxWM4DQAA4YNyFKKGDolSUmykbFs6WMkZawAABArlKIT5Dq0x7ggAgIChHIUw3xlrjDsCACBgKEchzDfXEXuOAAAIGMpRCBs7rH1QNnuOAAAIHMpRCBuXGi+pfUC2x2sbTgMAQHigHIWw4UkxckU41Nzm1bFTjabjAAAQFihHIczpsDQmpePQGuOOAAAICMpRiBvLZUQAAAgoylGI4zIiAAAEFuUoxHVeRoRyBABAYFCOQlxORoIkaWdJjVo9XsNpAAAIfZSjEDc2dYgSYyPV2OpRUUmN6TgAAIQ8ylE3CgoKlJOTo9zcXNNRPpHDYWnmqCRJUuGhk4bTAAAQ+ihH3cjPz1dRUZEKCwtNR+mRmdnJkihHAAAEAuUoDOR2lKP3Dp2SbTNTNgAA54JyFAamDHcrKsKhE/UtOlBZbzoOAAAhjXIUBlwRDk3PSpQkFR7k0BoAAOeCchQmcn3jjk4ZTgIAQGijHIWJ3NEMygYAIBAoR2HiwpGJcljSkZMNKq9pMh0HAICQRTkKE/HRkTq/Y7Zs9h4BANB3lKMw4n9KPwAA6BvKURjpLEdbOGMNAIA+oxyFkdzs9suI7C6rUU1Tq+E0AACEJspRGBmWEK1RQ2PltaVthzm0BgBAX1COwszMUYw7AgDgXFCOwsys0e2H1rZwxhoAAH1COQozMzsGZb9fXKXmNo/hNAAAhB7KUZgZkxKnoXEuNbd5teNYjek4AACEHMpRmLEsSzM7zlpjMkgAAHqPchSGTk8GSTkCAKC3KEdhqLMcFR46Ja/XNpwGAIDQQjkKQzmZCYqJdKq6sVX7jteZjgMAQEihHIWhSKdDF45KlMSlRAAA6C3KUZg6PRkk5QgAgN6gHIWpWaNPjzsCAAA9RzkKU9OzEuV0WDpW1ahjVY2m4wAAEDIoR2EqLipCkzMTJHFoDQCA3qAchbGZvlP6KUcAAPQU5SiM+eY7Osi4IwAAeopyFMY6LyOyp7xW1Q2thtMAABAaKEdhLGVIlMakxkmS3jvMoTUAAHqCchTmckdxSj8AAL1BOQpzuaMZlA0AQG9QjsJcbse4ow+OVqmp1WM4DQAAwY9yFOZGJsdqWHyUWj223i+uMh0HAICgRzkKc5Zl+U7pf+8w444AAPgklKNBoPOUfsYdAQDwyfpUjoqLi3X06FHf4y1btuiWW27R//7v/wYsGAKnc8/R1kOn5PHahtMAABDc+lSOvvKVr2jDhg2SpLKyMn32s5/Vli1b9IMf/EA/+tGPAhoQ5+78jAQNiYpQbXOb9pTVmo4DAEBQ61M52rFjh2bNmiVJevrppzV58mS98847evLJJ7Vu3bpA5kMAOB2WLhzFoTUAAHqiT+WotbVVUVFRkqTXXntNV1xxhSRp4sSJKi0tDVw6BEwu5QgAgB7pUzmaNGmSHn30Ub355pt69dVXdfnll0uSSkpKNHTo0IAGRGD4TwZp24w7AgDg4/SpHN1333361a9+pXnz5unqq6/WtGnTJEl/+ctffIfbEFymZyUq0mmpvKZZR081mo4DAEDQiujLi+bNm6fKykrV1NQoKSnJt/yGG25QbGxswMKZUlBQoIKCAnk84TOjdHSkU1OGu7XtSJW2HDyprOTQ//8JAID+0Kc9R42NjWpubvYVo8OHD2vNmjXas2ePhg0bFtCAJuTn56uoqEiFhYWmowTU6ckgGXcEAMDH6VM5WrJkiR5//HFJUlVVlfLy8vTAAw/oyiuv1COPPBLQgAicznK05SDlCACAj9OncrRt2zbNmTNHkvSnP/1JaWlpOnz4sB5//HE99NBDAQ2IwJnRccba/uP1OlHXbDgNAADBqU/lqKGhQfHx8ZKkV155RcuWLZPD4dCnPvUpHT58OKABEThJcS5NSBsiieusAQDwcfpUjsaNG6fnn39excXFevnll3XZZZdJkioqKpSQkBDQgAismZ3jjpjvCACAbvWpHN1555267bbblJ2drVmzZmn27NmS2vciXXDBBQENiMCa1Tnu6BB7jgAA6E6fTuX/4he/qE9/+tMqLS31zXEkSfPnz9fSpUsDFg6BNzO7fdzRzmPVamhpU6yrT18BAADCVp9/M6anpys9PV1Hjx6VJI0YMYIJIEPA8MQYZbijVVrdpO1HqnTRuBTTkQAACCp9Oqzm9Xr1ox/9SG63W6NGjdKoUaOUmJioH//4x/J6vYHOiACyLMt3Sn8hh9YAADhDn/Yc/eAHP9BvfvMb/exnP9PFF18sSXrrrbe0evVqNTU16Z577gloSARWbnaS/vJ+CRehBQCgG30qR4899ph+/etf64orrvAtmzp1qoYPH66bbrqJchTkOi9Cu+3IKbV5vIpw9mkHIgAAYalPvxVPnjypiRMnnrF84sSJOnmSvRHBbsKweCVER6ihxaOi0hrTcQAACCp9KkfTpk3T2rVrz1i+du1aTZ069ZxDoX85HJZvviPGHQEA0FWfDqvdf//9+vznP6/XXnvNN8fR5s2bVVxcrL///e8BDYj+MTM7Sa/vrtB7h07quk+PNh0HAICg0ac9R5dccok+/PBDLV26VFVVVaqqqtKyZcu0c+dOPfHEE4HOiH4wy7fn6KRs2zacBgCA4GHZAfzN+P777+vCCy+Ux+MJ1FsaVVNTI7fbrerq6rC7LEpzm0dTVr+iljavNtw2T6NT4kxHAgAgIM719zenKQ1SURFOTR+RKEkqPMggegAAOlGOBrHOS4kw3xEAAKdRjgaxzvmOKEcAAJzWq7PVli1bdtbnq6qqziULBtiFI5NkWdKhEw2qqG3SsPho05EAADCuV+XI7XZ/4vNf//rXzykQBo47JlIT0xO0q7RG7x06pc9NyTAdCQAA43pVjn73u9/1Vw4YkpudpF2lNSo8dJJyBACAGHM06OVmM+4IAAB/lKNBrvOMtaKSGtU1txlOAwCAeZSjQS7DHaMRSTHy2tK2w1xnDQAAyhF8lxJ5j0NrAABQjiDN7ChHWyhHAABQjiDNGt0+7mh7cZVa2ryG0wAAYBblCBqbOkRJsZFqavVqR0m16TgAABhFOYIsy/IdWmPcEQBgsKMcQVL7ZJCStOUgZ6wBAAY3yhEknZ4Mcuvhk/J6bcNpAAAwh3IESdKkTLeiIx061dCqA5V1puMAAGAM5QiSJFeEQxdkcWgNAADKEXw6xx29ufe44SQAAJhDOYLPZZPSJUnrd1WoqqHFcBoAAMygHMFnUmaCJqbHq8Xj1V8/KDUdBwAAIyhH8LEsS1+cMUKS9OetRw2nAQDADMoRulgyfbicDkvbi6u0r4Kz1gAAgw/lCF2kxkfpkgmpkqQ/b2PvEQBg8KEc4Qydh9ae23ZMHiaEBAAMMpQjnGH++cPkjolUWU2T3tlfaToOAAADinKEM0RFOLV4WoYkBmYDAAYfyhG6ddWF7YfWXtpZptqmVsNpAAAYOJQjdGt6VqLGpsapqdWrv/+bOY8AAIMH5QjdsixLV/nmPDpmOA0AAAOHcoSPtfSC4bIsacuhkzp8ot50HAAABgTlCB8rwx2jT49LkST9eRt7jwAAgwPlCGfVOefRs9uOysucRwCAQYByhLO6LCddQ6IidPRUo7YcOmk6DgAA/Y5yhLOKcTn1+SnMeQQAGDwoR/hEX5zZfmjt7/8uVUNLm+E0AAD0L8oRPtHMUUkaNTRW9S0evbSjzHQcAAD6FeUIn8iyLC27oGPOo20cWgMAhDfKEXpk2YXDJUnv7D+hkqpGw2kAAOg/lCP0SFZyrD41Jlm2LT33L+Y8AgCEL8oReqzzYrR/2npUts2cRwCA8EQ56kZBQYFycnKUm5trOkpQWTQlQzGRTh2srNe2I1Wm4wAA0C8oR93Iz89XUVGRCgsLTUcJKkOiIrRocrokBmYDAMIX5Qi90nk5kb++X6KmVo/hNAAABB7lCL3yqTFDNTwxRrVNbXq1qNx0HAAAAo5yhF5xOCwtvaD9tH4OrQEAwhHlCL3WOefRGx8eV0VNk+E0AAAEFuUIvTYmdYhmjEqS15ae386cRwCA8EI5Qp8w5xEAIFxRjtAnn5+aIVeEQx+W12nHsRrTcQAACBjKEfrEHROpy3LSJDEwGwAQXihH6LPOOY9e2H5MLW1ew2kAAAgMyhH6bM74VA2Lj9Kphla9vrvCdBwAAAKCcoQ+czLnEQAgDFGOcE6u6ji0tmF3hU7UNRtOAwDAuaMc4ZxMSIvX1BFutXlt/eX9EtNxAAA4Z5QjnLPOOY84tAYACAeUI5yzK6ZlKtJpacexGu0uY84jAEBooxzhnCXFuTR/YsecR1vZewQACG2UIwRE58Ds5/5VojYPcx4BAEIX5QgBMe+8VA2Nc6myrllv7q00HQcAgD6jHCEgIp0OXTE9U1L7xWgBAAhVlCMETOflRF4tKld1Q6vhNAAA9A3lCAEzKdOtienxavF49dcPmPMIABCaKEcIqM69R8x5BAAIVZQjBNSS6cPldFj615Eq7T9eZzoOAAC9RjlCQKXGR2nehFRJzHkEAAhNlCME3Ok5j47J47UNpwEAoHcoRwi4+ecPkzsmUqXVTXpj73HTcQAA6BXKEQIuKsLpuxjtff/YzYzZAICQQjlCv/jO/HFKio3U7rJa/f6fh03HAQCgxyhH6BeJsS59b+FESdIDr36o47XNhhMBANAzlCP0m+W5WZoy3K3apjbd/9Ju03EAAOgRyhH6jdNh6e4lkyRJz2w9qm1HThlOBADAJ6McoV9dODJJX5rZPjj7rhd2cmo/ACDoUY7Q726/fKLioyP072PVeqqw2HQcAADOinKEfpcyJEr/+dkJkqT7X96tU/UthhMBAPDxKEcYEF/71ChNTI9XVUOr/s8re0zHAQDgY1GOMCAinA7dfUX74Ow/bDmiHceqDScCAKB7lCMMmLwxQ7VkeqZsW7rzhR3yMjgbABCEKEcYUP/9ufMV53Jq25EqPfuvY6bjAABwBsoRBlRaQrS+M3+8JOln/9ilmqZWw4kAAOiKcoQBt/Li0RqTGqfKuhateXWv6TgAAHRBOcKAc0WcHpz92OZD2l1WYzgRAACnUY5gxJzxqVo0OV0er627Xtgp22ZwNgAgOFCOYMwPPn++oiMdevfgSf31g1LTcQAAkEQ5gkEjkmKVP2+cJOmevxWpvrnNcCIAAChHMOz6uWM0MjlW5TXNevj1fabjAABAOYJZ0ZFO3bU4R5L0m7cOaP/xOsOJAACDHeUIxs0/P02fmThMrR5bq//C4GwAgFmUIwSFO7+QI5fToTf3VurlneWm4wAABjHKEYJCdkqcbpg7RpL04xeL1NjiMZwIADBYUY4QNG66dKwy3dE6VtWoRzbtNx0HADBIUY4QNGJdEfp/v9A+OPvRTft15ESD4UQAgMGIcoSgsmhyuj49LkUtbV796MUi03EAAIMQ5QhBxbIsrb4iRxEOS6/tKteG3RWmIwEABhnKEYLOuGHx+sanR0uSVv91p5paGZwNABg4lCMEpW9/ZpyGxUfp8IkG/eatg6bjAAAGEcoRglJ8dKT++3PnS5Iefn2vjlU1Gk4EABgsKEcIWkumZyo3O0lNrV799G+7TMcBAAwSlCMELcuydPcVk+WwpL/9u1SPbz5kOhIAYBCgHCGo5WQm6LvzJ0iS7nxhp57ddtRwIgBAuKMcIeh9Z/44XXtRtiTpe3/6QC/tKDMbCAAQ1ihHCHqWZenOL+ToizNGyOO19Z0//ktv7j1uOhYAIExRjhASHA5LP1s2RYsmp6vF49UNj2/V1sMnTccCAIQhyhFCRoTToTVfnq4541PU2OrRtb8r1M6SatOxAABhhnKEkBIV4dSvrpmhmaOSVNvUpq//Zov2H68zHQsAEEYoRwg5sa4I/XZlriZlJuhEfYu+9ut3dfRUg+lYAIAwQTlCSEqIjtTj35ilsalxKq1u0td+/a4qaptMxwIAhAHKEULW0CFR+v038zQ8MUaHTjTo67/ZoqqGFtOxAAAhjnKEkJbhjtGT38xTanyUdpfV6trfFaquuc10LABACKMcIeRlp8Tp99flKTE2UtuLq3TD4++pqdVjOhYAIERRjhAWzkuP12MrZynO5dQ7+0/o5j9sU6vHazoWACAEUY4QNqZlJerXK3IVFeHQa7sqdNsz78vrtU3HAgCEGMoRwsrssUP1yNcuVITD0gvbS/TDF3bItilIAICeoxwh7HxmYpr+Z/l0WZb05LtHdN9Le0xHAgCEEMoRwtLiaZn66dIpkqRHN+1XwYZ9hhMBAEIF5Qhh6+pZI/WDz50vSfr5y3v0+OZDZgMBAEIC5Qhh7fq5Y/Sdz4yTJN35wk49u+2o4UQAgGBHOULYu/WzE3TtRdmSpO/96QO9tKPUbCAAQFCjHCHsWZalO7+Qoy/OGCGP19aNv9+mu/+6U40tTBQJADgT5QiDgsNh6WfLpuireSMlSb97+5AW/eINvXfopOFkAIBgQznCoBHhdOiepVO0bmWu0hOidehEg/7jV5t1z9+KuNwIAMCHcoRBZ955w/TyrXP1xRkjZNvS/33zoD730Jv615FTpqMBAIIA5QiDkjsmUv/nP6bpNytmKjU+SgeO1+uqR97RfS/tVnMbe5EAYDCjHGFQm39+ml69da6WXjBcXlt6ZON+LX74LX1wtMp0NACAIZQjDHqJsS79z/Lp+tU1M5QyxKUPy+u09Jfv6IFX9qilzWs6HgBggFGOgA4LJ6XrlVsv0RemZsjjtfXw6/t0xdq3tLOk2nQ0AMAAohwBfpLjXFr7lQtV8JULlRzn0u6yWi1Z+7Z+8dpetXrYiwQAgwHlCOjG56dm6JVb5+rySelq89r6n9c+1JUFb2t3WY3paACAfkY5Aj5GypAoPfK1C/WLL0+XOyZSO0tqtPjht1SwYZ/a2IsEAGGLcgSchWVZWjJ9uF69da4WnD9MrR5bP395j6565B3tq6g1HQ8A0A8oR0APDEuI1v/9+kw9+KVpio+O0PtHq/W5h97S/S/tVkVtk+l4AIAAsmzbtk2HCFY1NTVyu92qrq5WQkKC6TgIEmXVTfqvZz/Qxj3HJUkup0NXXpCpb84Zowlp8YbTAQDO9fc35egsKEf4OLZt6+Wd5frfN/Zr25Eq3/JLJqTq+jljdPG4obIsy1xAABjEKEf9iHKEnth6+JR+/eYBvbyzTN6O/5rOz0jQ9XNG6wtTM+WK4Og1AAwkylE/ohyhNw6fqNdv3zqop987qsbW9uuzpSVE6dqLRusreSPljok0nBAABgfKUQ8sXbpUGzdu1Pz58/WnP/2px6+jHKEvqhpa9OS7R7TunUM6XtssSYp1ObU8N0vfuHi0spJjDScEgPBGOeqBjRs3qra2Vo899hjlCAOmuc2jv2wv0a/fPKg95e2n/TssadHkDH1zzmhdMDLJcEIACE/n+vt7UAyGmDdvnuLjOYsIAysqwqn/mJmll26Zo8e/MUtzxqfIa0t/+3eplv7yHX3xkXf08s4yebxh/+8TAAgpxsvRG2+8ocWLFyszM1OWZen5558/Y52CggJlZ2crOjpaeXl52rJly8AHBfrIsizNnZCqJ67L0z++O0dXXThCkU5L7x0+pf/nia2a/8BGPbH5kE7UNZuOCgCQFGE6QH19vaZNm6ZvfOMbWrZs2RnPP/XUU1q1apUeffRR5eXlac2aNVq4cKH27NmjYcOGSZKmT5+utra2M177yiuvKDMzs8dZmpub1dx8+hdUTQ3X0UJgnZ+RoAe+NE23X36eHnvnkH7/z8M6dKJBP3xhp374wk5NykzQnPGpmjs+RTOykxQV4TQdGQAGnaAac2RZlp577jldeeWVvmV5eXnKzc3V2rVrJUler1dZWVn69re/rf/6r//q8Xtv3LhRa9euPeuYo9WrV+vuu+8+YzljjtBf6pvb9Mx7xfr/Cou1u6zr5UiiIx3KGz1Uc8anaM74VE1IG8LcSQDQA+c65sj4nqOzaWlp0datW3XHHXf4ljkcDi1YsECbN28O+OfdcccdWrVqle9xTU2NsrKyAv45QKe4qAhde/FoXXvxaFXUNuntfZV688NKvbmvUsdrm7Xpw+Pa9OFxSbs0LD5Knx6fornjU3XxuBSlxkeZjg8AYSmoy1FlZaU8Ho/S0tK6LE9LS9Pu3bt7/D4LFizQ+++/r/r6eo0YMULPPPOMZs+efcZ6UVFRioriFw7MGBYfraUXjNDSC0bItm3tKa/1FaV3D5xQRW2znt12TM9uOyap/RDd3I69SjOzkxQdySE4AAiEoC5HgfLaa6+ZjgD0imVZmpieoInpCbp+7hg1tXq09fApvbH3uN78sFJFpTXa1fHzqzcOKCrCoVmjkzVnfIouGpuiCWnxzMwNAH0U1OUoJSVFTqdT5eXlXZaXl5crPT3dUCpg4EVHOnXxuBRdPC5FdyySKuua2w/B7a3Um3uPq7ymueN+pSQpwmFpdEqcJqTH67y0eE1Ii9d56fEamRwrp4NxSwBwNkFdjlwul2bMmKH169f7Bml7vV6tX79eN998s9lwgEEpQ6K0ZPpwLZk+XLZta19Fnd7YW6m39h7Xe4dOqba5TXsr6rS3ok5/U6nvdVERDo1PG6IJnYUpLV4T0uOV6Y5msDcAdDBejurq6rRv3z7f44MHD2r79u1KTk7WyJEjtWrVKq1YsUIzZ87UrFmztGbNGtXX12vlypUGUwPBw7IsjU+L1/i0eF336dGybVul1U3aU16rveW12lNWpw/La7W3olZNrV7tOFajHce6TlMRHxWh8WlDdF5619KUMoQxeAAGH+On8m/cuFGXXnrpGctXrFihdevWSZLWrl2rn//85yorK9P06dP10EMPKS8vr9+zcfkQhBOP11bxyQbtKa/Vh2W17bfltTpwvF5tHzNLd0J0hDITY5ThjlZGYowy3dHKcMcoIzFame4YpbujGQgOIOhwbbV+RDnCYNDS5tWhE/XaU9ZeljpvD59sUE/+dkiOc7WXJ3eMMhO73ma4o5WWEM3gcAADKqznOQLQ/1wRDt8YJH+NLR4Vn2pQSVWjSqub2n867pdUN6q0qkmNrR6drG/RyfoW7SzpfkZ5y2ofI5U6JEqJsZEdPy4lxnz0vuv08zEuChUAYyhHALoV43J2W5o62bat6sZWlVQ1qbS6USXVTSrrKE0l1acLVUubV8drm3W8tnfXjot1OZUU65K7o0Qlxbrkjo1UYkyk4qIiFOdyKjYqQrEup+Jc7bexrgjFRrU/jnE5FedyKsJJyQLQO5QjAH1iWVbH3h6XcjK7321t27ZO1LeotKpJJ+qbVd3YqqqGVp1qaFFVQ6uqG8+8X93YKtuWGlo8amhp1LGqxnPK6YpwfKRAtZeouCinYlwRiopwyBXh8Lt1tt93OhQV6X/r7HZd/8cRDksRTocinZYiHO23nAUIhB7KEYB+Y1mWUoZE9eqsN6/XVm1TW3tpamxVVUd5qvI9blV9c1tHeWpTfcdtQ4tHDc0e1Xfc93QMMm9p86qlzauqhtb++mOeldNhKcJhKdLpUIRfaYpwWop0ONqf9xWq0/cdliWnw5Kz89ZhydHxOMLvvqPj/Z2OztdIToej/bbjeYdlyZLkcFiyLMlhWXJ03Fqdz1mdz59+zmFJlk6/xv9Wkm/dznWsjmWd9zvXtfzX6fi8zmXy3VfH/3R9P33kPTvXl/xy+K/XZZ2un+Gvu+fPWEfWGev7f96Z79v9+t297vR6Vg/W6WbhGe/dsxIejF3dsqQRSbGmY3RBOQIQVBwOS+7YSLljI/v8HrZtq8XjVWOLp708dZSp+pY2NTR71NDavqy+xeMrT81tno5bv8cer5pbvb7bZo9Xza0fXd7+uKXNq+5O+vN4bXm8tprbvOewVYDwFRPp1K4fX246RheUIwBhx7KsjsNjTiUO4D9IvV5brV6v2jy22jyn77d6vGrz2mrzeNXqsdXm7bjtWN7q6XiNt/25Nk97ofLYtrx+t20dRctr2/J4Ja/d/jlnW6/9p70wejteY6vj1pbv+fbHp9fxvaZj/c49cbYt2Wpfz5bd8bh93S73pfay2HHftk9/Zuc6nTrfs/M5+b2HulnWuX7na/1v5bdux8u7rvfR133keb936JLvzKUf+TN0Wf7R9+q6bnev6X5Bt4t69N7drtej9+rRW/m2YyBERwbfuEDKUTcKCgpUUFAgj8djOgqAEOJwWIpyOBXF36xASGOeo7NgniMAAELPuf7+Dr59WQAAAAZRjgAAAPxQjgAAAPxQjgAAAPxQjgAAAPxQjgAAAPxQjgAAAPxQjgAAAPxQjgAAAPxQjgAAAPxQjgAAAPxQjgAAAPxQjgAAAPxEmA4QzGzbltR+dV8AABAaOn9vd/4e7y3K0VnU1tZKkrKysgwnAQAAvVVbWyu3293r11l2X2vVIOD1elVSUqL4+HhZlhXQ966pqVFWVpaKi4uVkJAQ0PfGx2O7m8F2N4Ptbgbb3Qz/7R4fH6/a2lplZmbK4ej9CCL2HJ2Fw+HQiBEj+vUzEhIS+I/HALa7GWx3M9juZrDdzejc7n3ZY9SJAdkAAAB+KEcAAAB+KEeGREVF6a677lJUVJTpKIMK290MtrsZbHcz2O5mBHK7MyAbAADAD3uOAAAA/FCOAAAA/FCOAAAA/FCOAAAA/FCODCkoKFB2draio6OVl5enLVu2mI4U1lavXi3Lsrr8TJw40XSssPPGG29o8eLFyszMlGVZev7557s8b9u27rzzTmVkZCgmJkYLFizQ3r17zYQNI5+03a+99tozvv+XX365mbBh4t5771Vubq7i4+M1bNgwXXnlldqzZ0+XdZqampSfn6+hQ4dqyJAhuuqqq1ReXm4ocXjoyXafN2/eGd/3G2+8sVefQzky4KmnntKqVat01113adu2bZo2bZoWLlyoiooK09HC2qRJk1RaWur7eeutt0xHCjv19fWaNm2aCgoKun3+/vvv10MPPaRHH31U7777ruLi4rRw4UI1NTUNcNLw8knbXZIuv/zyLt//P/7xjwOYMPxs2rRJ+fn5+uc//6lXX31Vra2tuuyyy1RfX+9b59Zbb9Vf//pXPfPMM9q0aZNKSkq0bNkyg6lDX0+2uyRdf/31Xb7v999/f+8+yMaAmzVrlp2fn+977PF47MzMTPvee+81mCq83XXXXfa0adNMxxhUJNnPPfec77HX67XT09Ptn//8575lVVVVdlRUlP3HP/7RQMLw9NHtbtu2vWLFCnvJkiVG8gwWFRUVtiR706ZNtm23f7cjIyPtZ555xrfOrl27bEn25s2bTcUMOx/d7rZt25dccon93e9+95zelz1HA6ylpUVbt27VggULfMscDocWLFigzZs3G0wW/vbu3avMzEyNGTNGX/3qV3XkyBHTkQaVgwcPqqysrMt33+12Ky8vj+/+ANi4caOGDRum8847T9/61rd04sQJ05HCSnV1tSQpOTlZkrR161a1trZ2+b5PnDhRI0eO5PseQB/d7p2efPJJpaSkaPLkybrjjjvU0NDQq/flwrMDrLKyUh6PR2lpaV2Wp6Wlaffu3YZShb+8vDytW7dO5513nkpLS3X33Xdrzpw52rFjh+Lj403HGxTKysokqdvvfudz6B+XX365li1bptGjR2v//v367//+by1atEibN2+W0+k0HS/keb1e3XLLLbr44os1efJkSe3fd5fLpcTExC7r8n0PnO62uyR95Stf0ahRo5SZmakPPvhA3//+97Vnzx49++yzPX5vyhEGhUWLFvnuT506VXl5eRo1apSefvppXXfddQaTAf3vy1/+su/+lClTNHXqVI0dO1YbN27U/PnzDSYLD/n5+dqxYwfjGAfYx233G264wXd/ypQpysjI0Pz587V//36NHTu2R+/NYbUBlpKSIqfTecYZC+Xl5UpPTzeUavBJTEzUhAkTtG/fPtNRBo3O7zffffPGjBmjlJQUvv8BcPPNN+vFF1/Uhg0bNGLECN/y9PR0tbS0qKqqqsv6fN8D4+O2e3fy8vIkqVffd8rRAHO5XJoxY4bWr1/vW+b1erV+/XrNnj3bYLLBpa6uTvv371dGRobpKIPG6NGjlZ6e3uW7X1NTo3fffZfv/gA7evSoTpw4wff/HNi2rZtvvlnPPfecXn/9dY0ePbrL8zNmzFBkZGSX7/uePXt05MgRvu/n4JO2e3e2b98uSb36vnNYzYBVq1ZpxYoVmjlzpmbNmqU1a9aovr5eK1euNB0tbN12221avHixRo0apZKSEt11111yOp26+uqrTUcLK3V1dV3+dXbw4EFt375dycnJGjlypG655Rb95Cc/0fjx4zV69Gj98Ic/VGZmpq688kpzocPA2bZ7cnKy7r77bl111VVKT0/X/v37dfvtt2vcuHFauHChwdShLT8/X3/4wx/0wgsvKD4+3jeOyO12KyYmRm63W9ddd51WrVql5ORkJSQk6Nvf/rZmz56tT33qU4bTh65P2u779+/XH/7wB33uc5/T0KFD9cEHH+jWW2/V3LlzNXXq1J5/0Dmd64Y+e/jhh+2RI0faLpfLnjVrlv3Pf/7TdKSwtnz5cjsjI8N2uVz28OHD7eXLl9v79u0zHSvsbNiwwZZ0xs+KFSts224/nf+HP/yhnZaWZkdFRdnz58+39+zZYzZ0GDjbdm9oaLAvu+wyOzU11Y6MjLRHjRplX3/99XZZWZnp2CGtu+0tyf7d737nW6exsdG+6aab7KSkJDs2NtZeunSpXVpaai50GPik7X7kyBF77ty5dnJysh0VFWWPGzfO/t73vmdXV1f36nOsjg8DAACAGHMEAADQBeUIAADAD+UIAADAD+UIAADAD+UIAADAD+UIAADAD+UIAADAD+UIAADAD+UIAM4iOztba9asMR0DwACiHAEIGtdee63vOmvz5s3TLbfcMmCfvW7dOiUmJp6xvLCwUDfccMOA5QBgHheeBRDWWlpa5HK5+vz61NTUAKYBEArYcwQg6Fx77bXatGmTfvGLX8iyLFmWpUOHDkmSduzYoUWLFmnIkCFKS0vTNddco8rKSt9r582bp5tvvlm33HKLUlJSfFeef/DBBzVlyhTFxcUpKytLN910k+rq6iRJGzdu1MqVK1VdXe37vNWrV0s687DakSNHtGTJEg0ZMkQJCQn60pe+pPLyct/zq1ev1vTp0/XEE08oOztbbrdbX/7yl1VbW9u/Gw1AwFCOAASdX/ziF5o9e7auv/56lZaWqrS0VFlZWaqqqtJnPvMZXXDBBXrvvff00ksvqby8XF/60pe6vP6xxx6Ty+XS22+/rUcffVSS5HA49NBDD2nnzp167LHH9Prrr+v222+XJF100UVas2aNEhISfJ932223nZHL6/VqyZIlOnnypDZt2qRXX31VBw4c0PLly7ust3//fj3//PN68cUX9eKLL2rTpk362c9+1k9bC0CgcVgNQNBxu91yuVyKjY1Venq6b/natWt1wQUX6Kc//alv2W9/+1tlZWXpww8/1IQJEyRJ48eP1/3339/lPf3HL2VnZ+snP/mJbrzxRv3yl7+Uy+WS2+2WZVldPu+j1q9fr3//+986ePCgsrKyJEmPP/64Jk2apMLCQuXm5kpqL1Hr1q1TfHy8JOmaa67R+vXrdc8995zbhgEwINhzBCBkvP/++9qwYYOGDBni+5k4caKk9r01nWbMmHHGa1977TXNnz9fw4cPV3x8vK655hqdOHFCDQ0NPf78Xbt2KSsry1eMJCknJ0eJiYnatWuXb1l2dravGElSRkaGKioqevVnBWAOe44AhIy6ujotXrxY99133xnPZWRk+O7HxcV1ee7QoUP6whe+oG9961u65557lJycrLfeekvXXXedWlpaFBsbG9CckZGRXR5bliWv1xvQzwDQfyhHAIKSy+WSx+PpsuzCCy/Un//8Z2VnZysioud/fW3dulVer1cPPPCAHI72HeZPP/30J37eR51//vkqLi5WcXGxb+9RUVGRqqqqlJOT0+M8AIIbh9UABKXs7Gy9++67OnTokCorK+X1epWfn6+TJ0/q6quvVmFhofbv36+XX35ZK1euPGuxGTdunFpbW/Xwww/rwIEDeuKJJ3wDtf0/r66uTuvXr1dlZWW3h9sWLFigKVOm6Ktf/aq2bdumLVu26Otf/7ouueQSzZw5M+DbAIAZlCMAQem2226T0+lUTk6OUlNTdeTIEWVmZurtt9+Wx+PRZZddpilTpuiWW25RYmKib49Qd6ZNm6YHH3xQ9913nyZPnqwnn3xS9957b5d1LrroIt14441avny5UlNTzxjQLbUfHnvhhReUlJSkuXPnasGCBRozZoyeeuqpgP/5AZhj2bZtmw4BAAAQLNhzBAAA4IdyBAAA4IdyBAAA4IdyBAAA4IdyBAAA4IdyBAAA4IdyBAAA4IdyBAAA4IdyBAAA4IdyBAAA4IdyBAAA4Of/B16sJHb/xcoyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Final loss: {losses[-1]:.2e}\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.yscale('log')\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94393f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ylabel('Learning rate')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.plot(lr_vals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd43a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|| I - ΣAi†Ai ||2: 2.0865495303955807e-15\n",
      "Is predicted POVM valid? Yes\n",
      "Fidelities:  [0.7606210661909006, 0.7962350636570655, 0.812354961822311]\n",
      "Mean fidelity is 0.789737030556759\n"
     ]
    }
   ],
   "source": [
    "with th.no_grad():\n",
    "    factors_unstacked = unstack(factors, N=N, M=M).to('cpu')\n",
    "    pred_povm_full = th.matmul(factors_unstacked.conj().transpose(-1, -2), factors_unstacked)\n",
    "\n",
    "    print(f\"|| I - ΣAi†Ai ||2: {th.linalg.norm(th.eye(N) - sum(pred_povm_full), ord=2).item()}\")\n",
    "    print(f'Is predicted POVM valid? {\"Yes\" if check_povm(pred_povm_full) else \"No\"}')\n",
    "\n",
    "    Fs = [ povm_fidelity(pred_povm_full[i], true_povm[i]) for i in range(M) ]\n",
    "    print(\"Fidelities: \", Fs)\n",
    "    print(f\"Mean fidelity is {sum(Fs)/len(Fs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_matrix(\n",
    "#     targets.cpu().numpy()[:5],\n",
    "#     title=\"Target Probability Matrix\",\n",
    "#     cmap=\"viridis\",\n",
    "#     show_values= not False,\n",
    "#     xlabel=r\"$\\langle \\alpha_i|E_m|\\alpha_i\\rangle$\",\n",
    "#     ylabel=r\"$|\\alpha_i\\rangle$\",\n",
    "#     colorbar=True,\n",
    "#     figsize=(6, 5),\n",
    "#     vmin=None,\n",
    "#     vmax=None\n",
    "# )\n",
    "\n",
    "# plot_matrix(\n",
    "#     pred_probs.cpu().numpy()[:5],\n",
    "#     title=\"Predicted Probability Matrix\",\n",
    "#     cmap=\"viridis\",\n",
    "#     show_values= not False,\n",
    "#     xlabel=r\"$\\langle \\alpha_i|E_m|\\alpha_i\\rangle$\",\n",
    "#     ylabel=r\"$|\\alpha_i\\rangle$\",\n",
    "#     colorbar=True,\n",
    "#     figsize=(6, 5),\n",
    "#     vmin=None,\n",
    "#     vmax=None\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
